---
title: "P300 Speller with patient with ALS"
subtitle: "Progetto MOBD 2018/19"
author: "Conidi Andrea, Falvo Simone"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
source("main.R")
```

# Introduzione

Lo scopo del progetto è quello di predire correttamente i caratteri corrispondenti a sequenze di stimolazioni provenienti da un'interfaccia BCI.

Il lavoro svolto è stato quello di utilizzare tecniche di classificazione binaria per distinguere le istanze *target* da quelle *non target*. In particolare è stato utilizzato un classificatore di tipo SVM lineare con l'ausilio di tecniche di data augmentation e feature selection, inoltre è stata modificata la funzione di decisione in modo che, in corrispondenza di ogni iterazione di stimolazioni, vengano selezionate come target una sola riga ed una sola colonna.

Il classificatore è stato addestrato su una porzione del dataset fornito, l'altra porzione è stata utilizzata come test ed i risultati finali hanno mostrato...



# Data Understanding

```{r}
visualize_data(dfxy)
```



# Data Splitting

Per addestrare e testare il modello, il dataset è stato suddiviso in training set e test set con una proporzione 70-30.

Prima di effettuare lo split, è stata applicata una permutazione a blocchi di 120 righe, in modo da mantenere la sequenzialità delle iterazioni per ogni carattere, che viene poi sfruttata per determinare gli indici di riga e colonna corrispondenti al carattere target.



# Data Augmentation

Per aumentare l'accuratezza del modello, sono stati introdotti dati fittizi generati a partire da un sottoinsieme del training set.

Inizialmente si è provato a generare dati aggiungendo semplicemente del rumore bianco oppure effettuando piccole traslazioni temporali dei valori di tensione (in modo da rendere più "robusto" il modello a eventuali errori o ritardi di misurazione), ma ciò non ha prodotto buoni risultati in cross-validazione. La tecnica risultata efficace è stata quella di generare nuovi caratteri aventi come valori di misurazione la media delle istanze appartenenti alla stessa classe di due caratteri diversi.

Sperimentalmente si ottengono risultati migliori generando un numero di caratteri pari al 30\% di quelli presenti del dataset, ed ognuno di essi viene generato "mediando" il numero minimo di caratteri, perché all'aumentare di tale quantità si ottengono caratteri con meno rumore che differiscono troppo dal dataset originale.

```{r}
augmented_train <- rbind(training_set, 
                         generate_data(training_set, 0.3, meanchar_gen, n=2))
```



# Feature Selection

Le feature implementate sono state prese dall'articolo *A new approach for EEG feature extraction in P300-based lie detection*.
Tra le feature sugerite dall'articolo si è deciso di provare a utilizzare:

* Area Positiva
* Area Negativa
* Area assoluta : somma dei moduli delle due aree precedenti
* Crossing Zero: numero di volte in cui il segnale passa per zero
* Potenza del segnale: cacolata come potenza=x
* Valore di Picco Picco
* Time Window: intervallo di tempo tra il picco positivo e negativo

Alcune delle feature sono invece state implementate analizzando i dati nella fase di data understanding:

* Rising Time: conta gli istanti temporali in cui il segnale è crescente
* Correlazione P300: calcola dal training set il segnale medio corrispondente alla P300 e costruisce la          matrice di correlazione con tutte le misurazioni.
* C_bin: matrice binaria calcolata a partire dal file C.txt, dove l'elemento c_bin[i,j]=1 se c[i]=j

La scelta delle features è stata fatta valutando le varie combinazioni in cross validation. Il set migliore è stato quello composto da: Area Assoluta,P300 e Crossing Zero.

## Relief

Le features selezione sono state valutate tramite la Relief. Di seguito l'istogramma contenente le valutazioni degli attributi:
```{r message=FALSE, warning=FALSE}
use_relief(featured_train)
```


# Normalizzazione

A seguito dell'introduzione di nuove feature i dati vengono normalizzati applicando la seguente trasformazione su ogni colonna dei dataset:

\begin{displaymath}
Z_{train} = \frac{X_{train} - \overline{X}_{train}}{\sigma_{train}}
\qquad \quad
Z_{test} = \frac{X_{test} - \overline{X}_{train}}{\sigma_{train}}
\end{displaymath}

Dove $\overline{X}$ e $\sigma$ sono rispettivamente media campionaria e deviazione standard dei dati delle istanze relativi ad una feature.

I dati di test vengono scalati utilizzando media campionaria e deviazione standard dei dati di training, essendo quest'ultimi un campione più numeroso della stessa distribuzione.




# Training

Nella fase iniziale del progetto sono stati provati vari classificatori ma i risultati migliori si sono ottenuti con liblinear.
La scelta dei parametri di type e loss sono stati determinati in cross-validation ottenendo come set ottimale : type=7 e cost=0.01.

## Funzione di decisione

Funzione basata sul massimo invece che sul segno. Partendo dai decision values ottenuti dalla predict di liblinear si seleziona un blocco di 120 righe corrispondente a un carattere e ogni 12 righe vengono estratti gli indici riga e colonna  contenententi il valore massimo.
Il risultato per ogni carattere sarà una matrice di indici riga/colonna  target, con un numero di righe pari al numero di iterazioni. A tale matrice viene applicata la moda per colonne ottenendo  la combinazione più frequente. Dopodiché si genera il nuovo blocco di predizioni impostando come target le istanze corrispondenti agli indici selezionati. 



# Cross-Validazione

Tutti i parametri del progetto sono stati calibrati sulla base dei risultati ottenuti in fase di cross-validazione.

In questa fase è stata applicata la tecnica *K-fold* con un valore di k pari a 10.
```{r message=FALSE, warning=FALSE}
cv_results <- cross_validation(scaled_data$train, 
                               classifier = LiblineaR, 
                               type = 7, cost = 0.01, bias = TRUE, verbose = FALSE)
```
```{r}
print(cv_results)
```



# Risultati e Conclusioni

Infine il modello viene valutato sul test set, fornendo un'indicazione della percentuale di caratteri correttamenti classificati.

I risultati mostrano sul test un'accuretezza pari al 100%%, tale risultato è stato ottenuto con un seme iniziale pari a 123.

```{r}
accuracy <- test_accuracy(model, scaled_data$test)
#printf("Caratteri predetti correttamente: %.2f %%", accuracy * 100)
```



# How To Test

Per addestrare e testare il modello con un nuovo Test set bisogna accedere al file main_test.R, deccomentare la seguente sezione di codice sostituendo i nomi dei file con quelli del test..
```{r}
#dfx_test <- read.table("X_test.txt", header = FALSE)
#dfc_test <- read.table("C_test.txt", header = FALSE)
#dfy_test <- read.table("Y_test.txt", header = FALSE)
```