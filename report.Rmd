---
title: "P300 Speller with patient with ALS"
subtitle: "Progetto MOBD 2018/19"
author: "Conidi Andrea, Falvo Simone"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r include=FALSE}
load("env.RData")
```



# Introduzione

Lo scopo del progetto è quello di predire correttamente i caratteri corrispondenti a sequenze di stimolazioni provenienti da un'interfaccia BCI.

Il lavoro svolto è stato quello di utilizzare tecniche di classificazione binaria per distinguere le istanze *target* da quelle *non target*. In particolare è stato utilizzato un classificatore di tipo SVM lineare con l'ausilio di tecniche di data augmentation e feature selection, inoltre è stata modificata la funzione di decisione in modo che, in corrispondenza di ogni iterazione di stimolazioni, vengano selezionate come target una sola riga ed una sola colonna.

Il classificatore è stato addestrato su una porzione del dataset fornito, l'altra porzione è stata utilizzata come test ed i risultati finali hanno mostrato...



# Data Understanding

```{r}
visualize_data(dfxy)
```



# Data Splitting

Per addestrare e testare il modello, il dataset è stato suddiviso in training set e test set con una proporzione 70-30.

Prima di effettuare lo split, è stata applicata una permutazione a blocchi di 120 righe, in modo da mantenere la sequenzialità delle iterazioni per ogni carattere, che viene poi sfruttata per determinare gli indici di riga e colonna corrispondenti al carattere target.



# Data Augmentation

Per aumentare l'accuratezza del modello, sono stati introdotti dati fittizi generati a partire da un sottoinsieme del training set.

Inizialmente si è provato a generare dati aggiungendo semplicemente del rumore bianco oppure effettuando piccole traslazioni temporali dei valori di tensione (in modo da rendere più "robusto" il modello a eventuali errori o ritardi di misurazione), ma ciò non ha prodotto buoni risultati in cross-validazione. La tecnica risultata efficace è stata quella di generare nuovi caratteri aventi come valori di misurazione la media delle istanze appartenenti alla stessa classe di due caratteri diversi.

Sperimentalmente si ottengono risultati migliori generando un numero di caratteri pari al 30\% di quelli presenti del dataset, ed ognuno di essi viene generato "mediando" il numero minimo di caratteri, perché all'aumentare di tale quantità si ottengono caratteri con meno rumore che differiscono troppo dal dataset originale.

```{r}
augmented_train <- rbind(training_set, 
                         generate_data(training_set, 0.3, meanchar_gen, n=2))
```



# Feature Selection



# Normalizzazione

A seguito dell'introduzione di nuove feature i dati vengono normalizzati applicando la seguente trasformazione su ogni colonna dei dataset:

\begin{displaymath}
Z_{train} = \frac{X_{train} - \overline{X}_{train}}{\sigma_{train}}
\qquad \quad
Z_{test} = \frac{X_{test} - \overline{X}_{train}}{\sigma_{train}}
\end{displaymath}

Dove $\overline{X}$ e $\sigma$ sono rispettivamente media campionaria e deviazione standard dei dati delle istanze relativi ad una feature.

I dati di test vengono scalati utilizzando media campionaria e deviazione standard dei dati di training, essendo quest'ultimi un campione più numeroso della stessa distribuzione.



# Training



# Cross-Validazione

Tutti i parametri del progetto sono stati calibrati sulla base dei risultati ottenuti in fase di cross-validazione.

In questa fase è stata applicata la tecnica *K-fold* con un valore di k pari a 10.



# Risultati e Conclusioni




# How To


